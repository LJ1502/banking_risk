# banking_risk
This is repo for hackathon Codefest (Xenber)

Track 2: An LLM-Based Risk Assessment for AI Credit Scoring System
1. Industry Context:
Banks and fintech companies are increasingly using AI to improve credit scoring, moving
beyond traditional models that rely only on structured financial data. With the rise of
large language models (LLMs), financial institutions now have the ability to analyze
unstructured text—such as loan applications, customer messages, and transaction
descriptions—to capture deeper behavioural and risk-related insights. However, the use
of LLMs in credit scoring is still new, and the industry faces challenges around
transparency, fairness, compliance, and reliability.
2. Problem Statement:
How can a reliable and transparent LLM-based risk assessment method evaluate credit
risk in AI-driven credit scoring systems?
3. Challenge:
Build a prototype using a Large Language Model (LLM) that assesses credit risk for
individuals or businesses.
4. AI Opportunity:
○ LLMs can extract insights from unstructured data.
○ AI can combine multiple data modalities (numerical + text) for more accurate risk
assessment
5. Optional Resources:
○ Open financial datasets (e.g., LendingClub, Kaggle credit datasets)
○ Synthetic transactional or business textual data
○ LLM APIs (OpenAI, HuggingFace)
○ Python ML libraries for tabular + text data integration
6. Judging Criteria:
○ Does the model improve credit decision-making?
○ How effectively does the LLM leverage textual data alongside structured data?
○ Interpretable for humans
○ UI/dashboard clarity, usability, and end-to-end functionality
